{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89ab3dff-bf21-4e7a-a147-19c193bcc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader, download_loader, ComposableGraph, GPTListIndex, GPTFaissIndex, GPTTreeIndex\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "\n",
    "def load_faiss_index(index_name=\"faiss_index.json\", path=\"./index/faiss_index.index\"):\n",
    "    #path = os.path.join(path, index_name)\n",
    "    return GPTFaissIndex.load_from_disk(\n",
    "        index_name, \n",
    "        faiss_index_save_path=path\n",
    "    )\n",
    "def create_faiss_index(documents):\n",
    "    # dimensions of text-ada-embedding-002\n",
    "    d = 1536 \n",
    "    faiss_index = faiss.IndexFlatL2(d)\n",
    "    index = GPTFaissIndex.from_documents(documents, faiss_index=faiss_index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8607e33-ddfd-4f3d-8d9a-2ebb8b2411db",
   "metadata": {},
   "source": [
    "### Compare 3 index for example wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "983eed99-a104-4f91-a8fa-d665616d26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(input_files=['./data/backtest-create.rtf']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c265ea3b-13d4-4dc1-acc8-b2ac88bc0278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 5412 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 5412 tokens\n"
     ]
    }
   ],
   "source": [
    "indices = [\n",
    "    GPTSimpleVectorIndex.from_documents(documents), \n",
    "    GPTTreeIndex.from_documents(documents),\n",
    "    create_faiss_index(documents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b9061d-650e-4700-8b97-51deff41b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_doc_index = load_faiss_index(\"./index/online_doc_index.json\", \"./index/online_doc_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef28a9d0-57a3-4421-b071-973dc1f91d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.playground import Playground\n",
    "\n",
    "playground = Playground(indices=indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5bf94-6452-4f27-93d7-995f08bea8b6",
   "metadata": {},
   "source": [
    "### Ask a sample question and compare the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fd746c0-2147-46e7-8ca8-4591a15c131f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mQuery:\u001b[0m\n",
      "how to create a new backteest?\n",
      "\n",
      "Trying 15 combinations...\n",
      "\n",
      "\n",
      "\u001b[1mGPTSimpleVectorIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4007 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "To create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. Additionally, you can use Profit Actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTSimpleVectorIndex\u001b[0m, mode = embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4007 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n",
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "To create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. Additionally, you can use Profit Actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.leaf_query:>[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 7702 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.tree.summarize_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mTo create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. You can also use profit actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = summarize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 1 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 6445 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m\n",
      "To create a new backtest, click the \"New Backtest\" button at the top of the page. This will open a new backtest window where you can select the tickers you want to backtest (SPY, SPX, QQQ, and IWM) and the date range (1/1/13 to yesterday). Under the “Strategy” section, choose from the list of common strategies or create a custom strategy by clicking the “Add Leg” option. Select the strike selection type and option legs. Link the legs if necessary. Set entry conditions such as entry time, frequency, and specific dates. Set starting funds, margin allocation % per trade, max open trades, max contracts per trade, and use VIX. Set exit conditions such as profit target and stop loss. You can also save and share your backtest by selecting the down arrow next to the New Backtest button.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4007 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 5421 tokens\n",
      "INFO:llama_index.indices.tree.retrieve_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mTo create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. Additionally, you can use Profit Actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = retrieve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3594 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m\n",
      "To create a new backtest, hit the “New Backtest” button on your dashboard. You can also save and share a backtest by selecting the down arrow next to the New Backtest button and toggling the option in the “save/edit” backtest slider.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTFaissIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4007 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "To create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. Additionally, you can use Profit Actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTFaissIndex\u001b[0m, mode = embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4006 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "To create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. You can also use profit actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\n",
      "Ran 8 combinations in total.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Output</th>\n",
       "      <th>Duration</th>\n",
       "      <th>LLM Tokens</th>\n",
       "      <th>Embedding Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPTSimpleVectorIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>\\n\\nTo create a new backtest, hit the “New Bac...</td>\n",
       "      <td>3.619419</td>\n",
       "      <td>4007</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPTSimpleVectorIndex</td>\n",
       "      <td>embedding</td>\n",
       "      <td>\\n\\nTo create a new backtest, hit the “New Bac...</td>\n",
       "      <td>4.734237</td>\n",
       "      <td>4007</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>To create a new backtest, hit the “New Backtes...</td>\n",
       "      <td>8.726506</td>\n",
       "      <td>7702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>summarize</td>\n",
       "      <td>\\nTo create a new backtest, click the \"New Bac...</td>\n",
       "      <td>10.940973</td>\n",
       "      <td>6445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>embedding</td>\n",
       "      <td>To create a new backtest, hit the “New Backtes...</td>\n",
       "      <td>4.398623</td>\n",
       "      <td>4007</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>retrieve</td>\n",
       "      <td>\\nTo create a new backtest, hit the “New Backt...</td>\n",
       "      <td>2.750765</td>\n",
       "      <td>3594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPTFaissIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>\\n\\nTo create a new backtest, hit the “New Bac...</td>\n",
       "      <td>3.775957</td>\n",
       "      <td>4007</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPTFaissIndex</td>\n",
       "      <td>embedding</td>\n",
       "      <td>\\n\\nTo create a new backtest, hit the “New Bac...</td>\n",
       "      <td>3.808340</td>\n",
       "      <td>4006</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Index       Mode   \n",
       "0  GPTSimpleVectorIndex    default  \\\n",
       "1  GPTSimpleVectorIndex  embedding   \n",
       "2          GPTTreeIndex    default   \n",
       "3          GPTTreeIndex  summarize   \n",
       "4          GPTTreeIndex  embedding   \n",
       "5          GPTTreeIndex   retrieve   \n",
       "6         GPTFaissIndex    default   \n",
       "7         GPTFaissIndex  embedding   \n",
       "\n",
       "                                              Output   Duration  LLM Tokens   \n",
       "0  \\n\\nTo create a new backtest, hit the “New Bac...   3.619419        4007  \\\n",
       "1  \\n\\nTo create a new backtest, hit the “New Bac...   4.734237        4007   \n",
       "2  To create a new backtest, hit the “New Backtes...   8.726506        7702   \n",
       "3  \\nTo create a new backtest, click the \"New Bac...  10.940973        6445   \n",
       "4  To create a new backtest, hit the “New Backtes...   4.398623        4007   \n",
       "5  \\nTo create a new backtest, hit the “New Backt...   2.750765        3594   \n",
       "6  \\n\\nTo create a new backtest, hit the “New Bac...   3.775957        4007   \n",
       "7  \\n\\nTo create a new backtest, hit the “New Bac...   3.808340        4006   \n",
       "\n",
       "   Embedding Tokens  \n",
       "0                 9  \n",
       "1                 9  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4              5421  \n",
       "5                 0  \n",
       "6                 9  \n",
       "7                 9  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playground.compare(\"how to create a new backteest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdcc24c-c27e-4662-9112-33c7a1fbd76b",
   "metadata": {},
   "source": [
    "### TreeIndex - retrieve takes min time, use less LLM token and have a good answer. Winner!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6c24c-ee4e-4103-ac96-886f6c04507d",
   "metadata": {},
   "source": [
    "## Round 2 - how does TreeIndex perform with Knowledge graph index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a69bf0da-731d-42ca-8350-891dc25d1ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 5692 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.knowledge_graph.base import GPTKnowledgeGraphIndex\n",
    "\n",
    "KG_index = GPTKnowledgeGraphIndex.from_documents(\n",
    "    documents, \n",
    "    max_triplets_per_chunk=2\n",
    ")\n",
    "indices = [\n",
    "    GPTTreeIndex.from_documents(documents),\n",
    "    KG_index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5508c00c-8dd4-4f1c-ad90-5242f00b55ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mQuery:\u001b[0m\n",
      "how to create a new backteest?\n",
      "\n",
      "Trying 10 combinations...\n",
      "\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.leaf_query:>[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 7703 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.tree.summarize_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mTo create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. Additionally, you can use Profit Actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = summarize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 1 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 6490 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "To create a new backtest, click the \"New Backtest\" button at the top of the page. This will open a new backtest window where you can select the tickers you want to backtest (SPY, SPX, QQQ, and IWM) and the date range (1/1/13 to yesterday). Under the “Strategy” section, choose from the list of common strategies or create a custom strategy by clicking the “Add Leg” option. Select the strike selection type and option legs. Link the legs if necessary. Set entry conditions such as entry time, frequency, and specific dates. Set starting funds, margin allocation % per trade, max open trades, max contracts per trade, and use VIX. Set exit conditions such as profit target and stop loss. You can also save and share your backtest by selecting the down arrow next to the New Backtest button. This will open a slider where you can save and share your backtest.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4007 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 5421 tokens\n",
      "INFO:llama_index.indices.tree.retrieve_query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mTo create a new backtest, hit the “New Backtest” button on your dashboard. You can then set a stop loss based on a percentage, fixed profit, closing order, or per-leg stop loss. Additionally, you can use Profit Actions to scale out of a percentage of each trade at certain profit targets, adjust your stop loss, or both.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = retrieve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3594 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.knowledge_graph.query:> Starting query: how to create a new backteest?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "To create a new backtest, hit the “New Backtest” button on your dashboard. You can also save and share a backtest by selecting the down arrow next to the New Backtest button and toggling the option in the “save/edit” backtest slider.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTKnowledgeGraphIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.knowledge_graph.query:> Query keywords: ['backtest', 'new', 'create']\n",
      "ERROR:llama_index.indices.knowledge_graph.query:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.query:> Extracted relationships: The following are knowledge triplets in the form of (subset, predicate, object):\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 245 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m\n",
      "To create a new backtest, you will need to gather data, create a model, and then test the model against the data. Depending on the type of backtest, you may need to use different tools and techniques. For example, if you are creating a backtest for a trading strategy, you may need to use a trading simulator or a backtesting platform. Once you have gathered the data and created the model, you will need to run the backtest and analyze the results.\u001b[0m\n",
      "\n",
      "\n",
      "Ran 5 combinations in total.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Output</th>\n",
       "      <th>Duration</th>\n",
       "      <th>LLM Tokens</th>\n",
       "      <th>Embedding Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>To create a new backtest, hit the “New Backtes...</td>\n",
       "      <td>12.033060</td>\n",
       "      <td>7703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>summarize</td>\n",
       "      <td>\\nTo create a new backtest, click the \"New Bac...</td>\n",
       "      <td>15.307041</td>\n",
       "      <td>6490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>embedding</td>\n",
       "      <td>To create a new backtest, hit the “New Backtes...</td>\n",
       "      <td>5.020908</td>\n",
       "      <td>4007</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>retrieve</td>\n",
       "      <td>\\nTo create a new backtest, hit the “New Backt...</td>\n",
       "      <td>2.942588</td>\n",
       "      <td>3594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPTKnowledgeGraphIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>\\nTo create a new backtest, you will need to g...</td>\n",
       "      <td>3.351870</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Index       Mode   \n",
       "0            GPTTreeIndex    default  \\\n",
       "1            GPTTreeIndex  summarize   \n",
       "2            GPTTreeIndex  embedding   \n",
       "3            GPTTreeIndex   retrieve   \n",
       "4  GPTKnowledgeGraphIndex    default   \n",
       "\n",
       "                                              Output   Duration  LLM Tokens   \n",
       "0  To create a new backtest, hit the “New Backtes...  12.033060        7703  \\\n",
       "1  \\nTo create a new backtest, click the \"New Bac...  15.307041        6490   \n",
       "2  To create a new backtest, hit the “New Backtes...   5.020908        4007   \n",
       "3  \\nTo create a new backtest, hit the “New Backt...   2.942588        3594   \n",
       "4  \\nTo create a new backtest, you will need to g...   3.351870         245   \n",
       "\n",
       "   Embedding Tokens  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2              5421  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playground = Playground(indices=indices)\n",
    "playground.compare(\"how to create a new backteest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d523fbd-40bd-42ff-bf67-d78fa4b5aca5",
   "metadata": {},
   "source": [
    "### Conclusion: Although KnowledgeGraph uses less LLMToken(->$), the answer is kind of vague and long. I think TreeIndex-retrieve still wins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a7497-e064-4807-b9f7-b9d6e40d3bbc",
   "metadata": {},
   "source": [
    "## Same excercise but for question/answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ee116c3-658e-4d74-8376-55ef7d84bc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 3617 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 3479 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "JSONReader = download_loader(\"JSONReader\")\n",
    "json_loader = JSONReader()\n",
    "\n",
    "discord_help_questions = json_loader.load_data('./data/help-questions.json')\n",
    "\n",
    "KG_index = GPTKnowledgeGraphIndex.from_documents(\n",
    "    discord_help_questions, \n",
    "    max_triplets_per_chunk=2\n",
    ")\n",
    "qa_indices_ = [\n",
    "    GPTSimpleVectorIndex.from_documents(discord_help_questions), \n",
    "    GPTTreeIndex.from_documents(discord_help_questions),\n",
    "    KG_index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "838480e4-e8c9-4ed2-8782-ee02894c3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: What tickers can I test?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mQuery:\u001b[0m\n",
      "What tickers can I test?\n",
      "\n",
      "Trying 10 combinations...\n",
      "\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.leaf_query:>[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 7516 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.tree.summarize_query:> Starting query: What tickers can I test?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mYou can test SPY, SPX, QQQ, and IWM. You can also use Profit Actions to set profit targets, adjust your stop loss, or both. You can also use the per-leg stop loss option to close the trade on stop loss based on an individual selected leg.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = summarize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 1 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 5915 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: What tickers can I test?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "You can test SPY, SPX, QQQ, and IWM, as well as any other tickers that are available in the Option Omega platform.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3972 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n",
      "INFO:llama_index.indices.tree.retrieve_query:> Starting query: What tickers can I test?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mYou can test SPY, SPX, QQQ, and IWM. You can also use Profit Actions to set profit targets, adjust your stop loss, or both. You can also use the per-leg stop loss option to close the trade on stop loss based on an individual selected leg.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTTreeIndex\u001b[0m, mode = retrieve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3549 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.knowledge_graph.query:> Starting query: What tickers can I test?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "You can test SPY, SPX, QQQ, and IWM.\u001b[0m\n",
      "\n",
      "\u001b[1mGPTKnowledgeGraphIndex\u001b[0m, mode = default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.knowledge_graph.query:> Query keywords: ['Test', 'Tickers']\n",
      "ERROR:llama_index.indices.knowledge_graph.query:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.query:> Extracted relationships: The following are knowledge triplets in the form of (subset, predicate, object):\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 155 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m\n",
      "Unfortunately, without more information it is not possible to answer this question.\u001b[0m\n",
      "\n",
      "\n",
      "Ran 5 combinations in total.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Output</th>\n",
       "      <th>Duration</th>\n",
       "      <th>LLM Tokens</th>\n",
       "      <th>Embedding Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>You can test SPY, SPX, QQQ, and IWM. You can a...</td>\n",
       "      <td>4.940850</td>\n",
       "      <td>7516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>summarize</td>\n",
       "      <td>\\nYou can test SPY, SPX, QQQ, and IWM, as well...</td>\n",
       "      <td>3.759450</td>\n",
       "      <td>5915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>embedding</td>\n",
       "      <td>You can test SPY, SPX, QQQ, and IWM. You can a...</td>\n",
       "      <td>3.540539</td>\n",
       "      <td>3972</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPTTreeIndex</td>\n",
       "      <td>retrieve</td>\n",
       "      <td>\\nYou can test SPY, SPX, QQQ, and IWM.</td>\n",
       "      <td>1.534845</td>\n",
       "      <td>3549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPTKnowledgeGraphIndex</td>\n",
       "      <td>default</td>\n",
       "      <td>\\nUnfortunately, without more information it i...</td>\n",
       "      <td>1.038413</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Index       Mode   \n",
       "0            GPTTreeIndex    default  \\\n",
       "1            GPTTreeIndex  summarize   \n",
       "2            GPTTreeIndex  embedding   \n",
       "3            GPTTreeIndex   retrieve   \n",
       "4  GPTKnowledgeGraphIndex    default   \n",
       "\n",
       "                                              Output  Duration  LLM Tokens   \n",
       "0  You can test SPY, SPX, QQQ, and IWM. You can a...  4.940850        7516  \\\n",
       "1  \\nYou can test SPY, SPX, QQQ, and IWM, as well...  3.759450        5915   \n",
       "2  You can test SPY, SPX, QQQ, and IWM. You can a...  3.540539        3972   \n",
       "3             \\nYou can test SPY, SPX, QQQ, and IWM.  1.534845        3549   \n",
       "4  \\nUnfortunately, without more information it i...  1.038413         155   \n",
       "\n",
       "   Embedding Tokens  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 7  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playground.compare(\"What tickers can I test?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e83ba1-3368-4d0c-8428-87c8995e0fd0",
   "metadata": {},
   "source": [
    "### I would recommend TreeIndex - retrieve for both document source based on the response's simplicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbffbc64-0774-4186-8309-f8d95a44bed5",
   "metadata": {},
   "source": [
    "## Evaluation/Guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ab755ae-b475-4125-b67c-2f5f89aed140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "tree_index = GPTTreeIndex.from_documents(discord_help_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca34b304-70c3-422f-a271-ab3e517df6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.leaf_query:> Starting query: What tickers can I test?\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3531 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "response = tree_index.query(\"What tickers can I test?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6bee500-2754-44a1-a874-7ddcd20f6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index.evaluation import ResponseEvaluator\n",
    "from gpt_index import LLMPredictor, ServiceContext\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e3cc0e3-4ed7-4d78-b8e4-374976d89479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-3 (davinci)\n",
    "llm_predictor_gpt3 = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
    "service_context_gpt3 = ServiceContext.from_defaults(llm_predictor=llm_predictor_gpt3)\n",
    "\n",
    "evaluator = ResponseEvaluator(service_context=service_context_gpt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7877fce-c47b-40b9-bcc9-0f34e07f85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4042 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNO'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccb1d833-28ab-4101-a0d5-9aaccb66ec6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.retrieve_query:> Starting query: What tickers can I test?\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3531 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "response = tree_index.query(\"What tickers can I test?\", mode=\"retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5c4bca4-b541-4c3d-9e3e-4c6823943ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4044 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYES'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd5637-0dbb-4eb8-b75c-5151d9f72392",
   "metadata": {},
   "source": [
    "### Overall Suggestion: Pick 2 indexes, let them both do the query, and run this evaluation, and only send to Discord if reponse is YES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3375e-7ef3-46dd-b1a6-5184f9cd2f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-python38-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
